#!/usr/bin/env python3
"""
é›†æˆLLMåˆ†æçš„æ™ºèƒ½æ¼æ´æ£€æµ‹æµç¨‹
åœ¨åŸæœ‰çš„mainTest.pyåŸºç¡€ä¸Šå¢åŠ LLMè¾…åŠ©åˆ†æåŠŸèƒ½
"""

import logging
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from py2joern.cpgs.cpg import CPG
from py2joern.models.function import Function
from py2joern.models.semantics import Semantics
from py2joern.models.sink import Sink
from py2joern.models.source import Source
from py2joern.llmBridge.llmBridge import VulnerabilityLLMBridge
from py2joern.llmBridge.config import create_llm_client, LLMConfig, LLMProvider

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s %(message)s'
)
logger = logging.getLogger(__name__)

class MockLLMForIntegration:
    """é›†æˆæµ‹è¯•ç”¨çš„æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯"""
    
    def generate(self, prompt: str, **kwargs) -> str:
        """æ ¹æ®æç¤ºè¯ç±»å‹è¿”å›ç›¸åº”çš„æ¨¡æ‹Ÿå“åº”"""
        
        if "è¯­ä¹‰è§„åˆ™" in prompt or "semantic" in prompt.lower():
            return '''```json
            {
                "semantic_rules": [
                    {
                        "method_pattern": "strncpy",
                        "param_flows": [[2, 1]],
                        "is_regex": false,
                        "confidence": 0.9,
                        "reasoning": "strncpyå°†æºå­—ç¬¦ä¸²å®‰å…¨åœ°å¤åˆ¶åˆ°ç›®æ ‡ç¼“å†²åŒº"
                    },
                    {
                        "method_pattern": "^.*fgets$",
                        "param_flows": [[3, 1]],
                        "is_regex": true,
                        "confidence": 0.8,
                        "reasoning": "fgetsä»è¾“å…¥æµè¯»å–æ•°æ®åˆ°ç¼“å†²åŒº"
                    }
                ]
            }
            ```'''
        
        elif "æº" in prompt and "æ±‡èš" in prompt:
            return '''```json
            {
                "sources": [
                    {
                        "function_name": "input",
                        "parameter_index": -1,
                        "source_type": "ç”¨æˆ·è¾“å…¥",
                        "confidence": 0.95,
                        "reasoning": "inputå‡½æ•°è¿”å›ç”¨æˆ·è¾“å…¥çš„æ•°æ®"
                    }
                ],
                "sinks": [
                    {
                        "function_name": "dangerous_sink",
                        "parameter_index": 1,
                        "sink_type": "å±é™©æ“ä½œ",
                        "vulnerability_types": ["ç¼“å†²åŒºæº¢å‡º", "ä»£ç æ³¨å…¥"],
                        "confidence": 0.9,
                        "reasoning": "dangerous_sinkå‡½æ•°åæš—ç¤ºå…¶å¤„ç†å±é™©æ•°æ®"
                    }
                ]
            }
            ```'''
        
        elif "æ¼æ´" in prompt or "vulnerability" in prompt.lower():
            return '''```json
            {
                "is_vulnerable": true,
                "vulnerability_type": "ç¼“å†²åŒºæº¢å‡º",
                "severity": "é«˜",
                "confidence": 0.85,
                "attack_vector": "æ”»å‡»è€…å¯é€šè¿‡input()å‡½æ•°è¾“å…¥æ¶æ„æ•°æ®",
                "impact": "å¯èƒ½å¯¼è‡´ç¨‹åºå´©æºƒæˆ–ä»»æ„ä»£ç æ‰§è¡Œ",
                "remediation": "åœ¨dangerous_sinkä¸­æ·»åŠ è¾“å…¥éªŒè¯å’Œè¾¹ç•Œæ£€æŸ¥",
                "cwe_ids": ["CWE-120", "CWE-787"],
                "reasoning": "ä¸å—ä¿¡ä»»çš„ç”¨æˆ·è¾“å…¥ç›´æ¥ä¼ é€’ç»™å±é™©å‡½æ•°ï¼Œç¼ºä¹é€‚å½“éªŒè¯"
            }
            ```'''
        
        else:
            return "è¿™æ˜¯ä¸€ä¸ªæ™ºèƒ½åˆ†æçš„ç»“æœ"

class IntelligentVulnerabilityAnalyzer:
    """é›†æˆLLMçš„æ™ºèƒ½æ¼æ´åˆ†æå™¨"""
    
    def __init__(self, src_path: str, llm_client=None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        :param src_path: æºä»£ç è·¯å¾„
        :param llm_client: LLMå®¢æˆ·ç«¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯
        """
        self.src_path = src_path
        self.llm_client = llm_client or MockLLMForIntegration()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.cpg = None
        self.llm_analyzer = None
        self.semantics = None
        self.sources = []
        self.sinks = []
        
        logger.info(f"æ™ºèƒ½æ¼æ´åˆ†æå™¨åˆå§‹åŒ– - ç›®æ ‡: {src_path}")
    
    def initialize_analysis_environment(self):
        """åˆå§‹åŒ–åˆ†æç¯å¢ƒ"""
        logger.info("æ­¥éª¤1: åˆå§‹åŒ–åˆ†æç¯å¢ƒ...")
        
        # åˆ›å»ºCPG
        self.cpg = CPG(self.src_path)
        logger.info(f"âœ“ CPGåˆ›å»ºå®Œæˆï¼Œå…±å‘ç° {len(self.cpg.functions)} ä¸ªå‡½æ•°")
        logger.info(f"  - å†…éƒ¨å‡½æ•°: {len(self.cpg.internal_functions)}")
        logger.info(f"  - å¤–éƒ¨å‡½æ•°: {len(self.cpg.external_functions)}")
        logger.info(f"  - æ“ä½œç¬¦å‡½æ•°: {len(self.cpg.operator_functions)}")
        
        # åˆ›å»ºLLMåˆ†æå™¨
        self.llm_analyzer = VulnerabilityLLMBridge(self.llm_client)
        logger.info("âœ“ LLMåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # æ‰“å°å¤–éƒ¨å‡½æ•°ä¿¡æ¯
        logger.info("å‘ç°çš„å¤–éƒ¨å‡½æ•°:")
        for func in self.cpg.external_functions:
            logger.info(f"  - {func.full_name}")
    
    def generate_intelligent_semantics(self):
        """ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½è¯­ä¹‰è§„åˆ™"""
        logger.info("æ­¥éª¤2: ä½¿ç”¨LLMç”Ÿæˆè¯­ä¹‰è§„åˆ™...")
        
        # è¿‡æ»¤å‡ºçœŸæ­£çš„å¤–éƒ¨å‡½æ•°ï¼ˆæ’é™¤æ“ä½œç¬¦ï¼‰
        real_external_funcs = [
            func for func in self.cpg.external_functions 
            if not func.full_name.startswith("<operator>")
        ]
        
        if real_external_funcs:
            logger.info(f"åˆ†æ {len(real_external_funcs)} ä¸ªå¤–éƒ¨å‡½æ•°:")
            for func in real_external_funcs:
                logger.info(f"  - {func.full_name}")
            
            # ä½¿ç”¨LLMåˆ†æç”Ÿæˆè¯­ä¹‰è§„åˆ™
            self.semantics = self.llm_analyzer.analyze_external_functions(real_external_funcs)
            logger.info(f"âœ“ ç”Ÿæˆäº† {len(self.semantics.rules)} æ¡è¯­ä¹‰è§„åˆ™")
            
            for i, rule in enumerate(self.semantics.rules, 1):
                logger.info(f"  è§„åˆ™{i}: {rule.method_full_name} -> {rule.param_flows}")
        else:
            logger.info("æœªå‘ç°éœ€è¦åˆ†æçš„å¤–éƒ¨å‡½æ•°ï¼Œä½¿ç”¨é»˜è®¤è¯­ä¹‰è§„åˆ™")
            self.semantics = Semantics.create_default()
        
        # æ‰‹åŠ¨æ·»åŠ ä¸€äº›é€šç”¨è§„åˆ™
        self.semantics.add_memory_operation_rules()
        self.semantics.add_string_operation_rules()
        
        logger.info(f"âœ“ æœ€ç»ˆå…±æœ‰ {len(self.semantics.rules)} æ¡è¯­ä¹‰è§„åˆ™")
    
    def identify_sources_and_sinks_intelligently(self):
        """ä½¿ç”¨LLMæ™ºèƒ½è¯†åˆ«æºå’Œæ±‡èšç‚¹"""
        logger.info("æ­¥éª¤3: æ™ºèƒ½è¯†åˆ«æºå’Œæ±‡èšç‚¹...")
        
        # ä½¿ç”¨LLMåˆ†æå†…éƒ¨å‡½æ•°
        self.sources, self.sinks = self.llm_analyzer.identify_sources_and_sinks(
            self.cpg.internal_functions
        )
        
        logger.info(f"âœ“ æ™ºèƒ½è¯†åˆ«ç»“æœ:")
        logger.info(f"  - æ•°æ®æº: {len(self.sources)} ä¸ª")
        for source in self.sources:
            logger.info(f"    * {source.name} (å‚æ•°ç´¢å¼•: {source.index})")
        
        logger.info(f"  - æ±‡èšç‚¹: {len(self.sinks)} ä¸ª")
        for sink in self.sinks:
            logger.info(f"    * {sink.name} (å‚æ•°ç´¢å¼•: {sink.index})")
    
    def execute_dataflow_analysis(self):
        """æ‰§è¡Œæ•°æ®æµåˆ†æ"""
        logger.info("æ­¥éª¤4: æ‰§è¡Œæ•°æ®æµåˆ†æ...")
        
        # åº”ç”¨è¯­ä¹‰è§„åˆ™å¹¶æ‰§è¡Œæ•°æ®æµåˆ†æ
        try:
            self.cpg.apply_semantics(self.semantics)
            logger.info("âœ“ æ•°æ®æµåˆ†æå®Œæˆ")
        except Exception as e:
            logger.warning(f"æ•°æ®æµåˆ†æé‡åˆ°é—®é¢˜: {e}")
    
    def perform_taint_analysis(self):
        """æ‰§è¡Œæ±¡ç‚¹åˆ†æ"""
        logger.info("æ­¥éª¤5: æ‰§è¡Œæ±¡ç‚¹åˆ†æ...")
        
        if not self.sources or not self.sinks:
            logger.warning("ç¼ºå°‘æºæˆ–æ±‡èšç‚¹ï¼Œè·³è¿‡æ±¡ç‚¹åˆ†æ")
            return
        
        # æ‰§è¡Œæºåˆ°æ±‡èšçš„æ±¡ç‚¹åˆ†æ
        for source in self.sources[:3]:  # é™åˆ¶åˆ†ææ•°é‡
            for sink in self.sinks[:3]:
                logger.info(f"åˆ†æè·¯å¾„: {source.name} -> {sink.name}")
                
                try:
                    result = self.cpg.taint_analysis(source, sink)
                    if result:
                        logger.info(f"âœ“ å‘ç°æ•°æ®æµè·¯å¾„")
                        # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥ä½¿ç”¨LLMåˆ†æè·¯å¾„çš„å®‰å…¨æ€§
                    else:
                        logger.info("âœ— æœªå‘ç°æ•°æ®æµè·¯å¾„")
                except Exception as e:
                    logger.warning(f"æ±¡ç‚¹åˆ†æå¤±è´¥: {e}")
    
    def generate_analysis_report(self):
        """ç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š"""
        logger.info("æ­¥éª¤6: ç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š...")
        
        analysis_results = {
            "project_path": self.src_path,
            "total_functions": len(self.cpg.functions),
            "internal_functions": len(self.cpg.internal_functions),
            "external_functions": len(self.cpg.external_functions),
            "semantic_rules_generated": len(self.semantics.rules),
            "sources_identified": len(self.sources),
            "sinks_identified": len(self.sinks),
            "analysis_summary": {
                "llm_enhanced": True,
                "semantic_rules_auto_generated": len(self.semantics.rules) > 0,
                "intelligent_source_sink_detection": len(self.sources) > 0 or len(self.sinks) > 0
            }
        }
        
        # ä½¿ç”¨LLMç”ŸæˆæŠ¥å‘Š
        report = self.llm_analyzer.generate_security_report(analysis_results)
        
        logger.info("=" * 60)
        logger.info("æ™ºèƒ½åˆ†ææŠ¥å‘Š")
        logger.info("=" * 60)
        logger.info(report)
        logger.info("=" * 60)
        
        return report
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´çš„æ™ºèƒ½åˆ†ææµç¨‹"""
        logger.info("å¼€å§‹æ™ºèƒ½æ¼æ´æ£€æµ‹åˆ†æ...")
        logger.info("=" * 60)
        
        try:
            # æ‰§è¡Œåˆ†ææµç¨‹
            self.initialize_analysis_environment()
            self.generate_intelligent_semantics()
            self.identify_sources_and_sinks_intelligently()
            self.execute_dataflow_analysis()
            self.perform_taint_analysis()
            report = self.generate_analysis_report()
            
            logger.info("âœ“ æ™ºèƒ½åˆ†æå®Œæˆ!")
            return report
            
        except Exception as e:
            logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    # æµ‹è¯•è·¯å¾„
    test_src = "/home/nstl/data/vuln_hunter/py2joern/test/test_case/test1"
    
    print("æ™ºèƒ½æ¼æ´æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    print(f"åˆ†æç›®æ ‡: {test_src}")
    print("=" * 60)
    
    try:
        # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œ
        analyzer = IntelligentVulnerabilityAnalyzer(test_src)
        report = analyzer.run_complete_analysis()
        
        print("\n" + "=" * 60)
        print("åˆ†æå®Œæˆ! ğŸ‰")
        print("=" * 60)
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­åˆ†æ")
    except Exception as e:
        logger.error(f"åˆ†æå¤±è´¥: {e}")
        print(f"åˆ†æå¤±è´¥: {e}")

def test_with_real_llm():
    """æµ‹è¯•çœŸå®LLMå®¢æˆ·ç«¯"""
    print("\næµ‹è¯•çœŸå®LLMå®¢æˆ·ç«¯è¿æ¥...")
    
    try:
        # å°è¯•åˆ›å»ºOpenAIå®¢æˆ·ç«¯
        config = LLMConfig(
            provider=LLMProvider.OPENAI,
            model="gpt-3.5-turbo",
            max_tokens=1024,
            temperature=0.1
        )
        
        llm_client = create_llm_client(config)
        
        # åˆ›å»ºåˆ†æå™¨
        test_src = "/home/nstl/data/vuln_hunter/py2joern/test/test_case/test1"
        analyzer = IntelligentVulnerabilityAnalyzer(test_src, llm_client)
        
        print("âœ“ çœŸå®LLMå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
        
        # å¯ä»¥åœ¨è¿™é‡Œè¿è¡ŒçœŸå®åˆ†æ
        # analyzer.run_complete_analysis()
        
    except Exception as e:
        print(f"çœŸå®LLMå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        print("å›é€€åˆ°æ¨¡æ‹Ÿå®¢æˆ·ç«¯è¿›è¡Œæ¼”ç¤º")

if __name__ == "__main__":
    # è¿è¡Œä¸»è¦æ¼”ç¤º
    main()
    
    # å¯é€‰: æµ‹è¯•çœŸå®LLMå®¢æˆ·ç«¯
    # test_with_real_llm()
